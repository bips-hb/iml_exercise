{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10758e62",
   "metadata": {},
   "source": [
    "# Interpretable Machine Learning\n",
    "## Exercise Sheet: 6\n",
    "## This exercise sheet covers chapters 8.6 and 9.1 from the IML book by Christoph Molnar\n",
    "\n",
    "Kristin Blesch (blesch@leibniz-bips.de)<br>\n",
    "Niklas Koenen (koenen@leibniz-bips.de)\n",
    "<hr style=\"border:1.5px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1940ab9",
   "metadata": {},
   "source": [
    "# 1) Global Surrogate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c96de7",
   "metadata": {},
   "source": [
    "**a)** Explain the method 'Global Surrogate' and give an example.  \n",
    "\n",
    "**Solution:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff02c05",
   "metadata": {},
   "source": [
    "With a global surrogate, interpretability comes from creating an intrinsic copy of the actual model. No new model is fitted on the training data $(X, Y)$, but an intrinsically interpretable model learns the behavior of the given model $\\hat{f}$, i.e. the actual outcome $Y$ is replaced by the model output $\\hat{Y} = \\hat{f}(X)$ and thus an intrinsic model is fitted on $(X, \\hat{Y})$, which by definition can be interpreted.  \n",
    "For example, a linear model or a decision tree can be used to learn the predictions of a neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06b46bc",
   "metadata": {},
   "source": [
    "**b)** How can we measure the performance of a global surrogate. What is the consequence if the model performs very bad but the surrogate very good?  \n",
    "\n",
    "**Solution:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6218e8a8",
   "metadata": {},
   "source": [
    "One way to measure how well the surrogate replicates the black box model is the R² measure:\n",
    "$$\n",
    "R^2=1-\\frac{SSE}{SST}=1-\\frac{\\sum_{i=1}^n(\\hat{y}_*^{(i)}-\\hat{y}^{(i)})^2}{\\sum_{i=1}^n(\\hat{y}^{(i)}-\\bar{\\hat{y}})^2}\n",
    "$$\n",
    "The performance of the black box model does not play a role in training the surrogate model. The interpretation of the surrogate model is still valid because it makes statements about the model and not about the real world. But of course the interpretation of the surrogate model becomes irrelevant if the black box model is bad, because then the black box model itself is irrelevant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9d4fbd",
   "metadata": {},
   "source": [
    "# 2) Individual Conditional Expectation (ICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e367ce",
   "metadata": {},
   "source": [
    "**a)** What is an individual conditional expectation (ICE) plot and what is its relation to the PDP? Also explain the variants c-ICE and d-ICE and their advantages.\n",
    "\n",
    "**Solution:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22ec08f",
   "metadata": {},
   "source": [
    "Individual Conditional Expectation (ICE) plots visualise one line per instance that shows how the instance’s prediction changes when a feature changes. This is therefore a local equivalent of the global PDP plots. Instead of calculating the mean of the lines of all instances, they are plotted one by one, i.e. an ICE plot visualizes the dependence of the prediction on a feature for each instance separately, resulting in one line per instance, compared to one line overall in partial dependence plots.  \n",
    "\n",
    "**centered ICE (c-ICE):** It is sometimes hard to compare the individual ICE lines because they always start at different values, i.e. they are shifted on the y-axis differently. A solution is provided by the c-ICE plot, which anchors the curves at the lower end of the feature: ($x^a$ anchor point)\n",
    "$$\n",
    "\\hat{f}_{cent}^{(i)}=\\hat{f}^{(i)}-\\mathbf{1}\\hat{f}(x^{a},x^{(i)}_{C})\n",
    "$$\n",
    "\n",
    "**derivative ICE (d-ICE):** To spot heterogeneity in a visually easier way, the individual derivatives of the prediction function of the corresponding feature can be considered. Furthermore, interactions can be revealed, since the derivatives must be constant in the case of no interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2a2148",
   "metadata": {},
   "source": [
    "**b)** We again consider the example from Sheet 4 Task 1, but in this case we train a decision tree via gradient boosting. Execute the following code, which is almost identical to the one in sheet 4, only with gradient boosting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b571cdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Get data\n",
    "cal_housing = fetch_california_housing()\n",
    "X = pd.DataFrame(cal_housing.data, columns=cal_housing.feature_names)\n",
    "y = cal_housing.target\n",
    "\n",
    "# Get train and test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
    "\n",
    "# Train model and calculate R²-score\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "model = HistGradientBoostingRegressor(random_state = 42)\n",
    "model.fit(X_train, y_train)\n",
    "print(f\"Test R2 score: {model.score(X_test, y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2866060f",
   "metadata": {},
   "source": [
    "Now create the ICE plot for each feature using the already known function [`PartialDependenceDisplay`](https://scikit-learn.org/stable/modules/generated/sklearn.inspection.PartialDependenceDisplay.html#sklearn-inspection-partialdependencedisplay).  \n",
    "\n",
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc6ddf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "fig, ax = plt.subplots(nrows = 2, ncols = 4,figsize=(24, 12))\n",
    "\n",
    "display = PartialDependenceDisplay.from_estimator(\n",
    "    model,\n",
    "    X_test,\n",
    "    [\"MedInc\", \"HouseAge\", \"AveRooms\", \"AveBedrms\", \"Population\", \"AveOccup\", \"Latitude\", \"Longitude\"],\n",
    "    kind=\"both\",\n",
    "    ice_lines_kw={\"color\": \"tab:blue\", \"alpha\": 0.1, \"linewidth\": 0.5},\n",
    "    pd_line_kw={\"color\": \"tab:orange\", \"linestyle\": \"--\", \"linewidth\": 3},\n",
    "    ax = ax\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f902f42",
   "metadata": {},
   "source": [
    "**Bonus:** Modify the predict function of the trained model to produce a c-ICE for the feature `MedInc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c68f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model predict function\n",
    "predict_fun = model.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8001b25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the normalizing constant for each ICE line\n",
    "X = X_test.copy()\n",
    "q_5 = X.quantile(0.05)[0]\n",
    "X.MedInc = q_5\n",
    "normalize_constant = predict_fun(X)\n",
    "\n",
    "# Define new predict function\n",
    "def new_predict(X):\n",
    "  pred = predict_fun(X) - normalize_constant\n",
    "  \n",
    "  return pred\n",
    "\n",
    "# Set the new predict function in our model and calculate again the ICE plot for feature 'MedInc'\n",
    "model.predict = new_predict\n",
    "display = PartialDependenceDisplay.from_estimator(\n",
    "    model,\n",
    "    X_test,\n",
    "    [\"MedInc\"],\n",
    "    kind=\"both\",\n",
    "    ice_lines_kw={\"color\": \"tab:blue\", \"alpha\": 0.1, \"linewidth\": 0.5},\n",
    "    pd_line_kw={\"color\": \"tab:orange\", \"linestyle\": \"--\", \"linewidth\": 3}\n",
    ")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
