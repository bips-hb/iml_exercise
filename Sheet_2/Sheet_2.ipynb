{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# Interpretable Machine Learning\n",
    "## Exercise Sheet: 2\n",
    "\n",
    "### This exercise sheet covers chapters 5.1+5.2 from the IML book by Christoph Molnar\n",
    "Kristin Blesch (blesch@leibniz-bips.de)<br>\n",
    "Niklas Koenen (koenen@leibniz-bips.de)\n",
    "<hr style=\"border:1.5px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# 1) Linear Regression\n",
    "The linear model is one of the first and best-studied models for regression\n",
    "problems. However, it makes some (strong) assumptions about the given data. \n",
    "In the following exercise, you will learn how to fit and interpret a linear \n",
    "model and investigate its limitations. \n",
    "\n",
    "Let's consider a linear regression model \n",
    "for three features $p=3$ of the form\n",
    "$$\n",
    "\\hat{f}(x) = \\beta_0 + x_1 \\beta_1 + x_2 \\beta_2 + x_3\\beta_3 = X \\beta\n",
    "$$\n",
    "and the data is given in the csv-file `sheet_2_lin_data.csv`.\n",
    "\n",
    "**a)** Load the data as a `pandas` data frame and visualize in a 2D plot how each \n",
    "feature ($X_1, X_2, X_3$) affects the output $Y$. Preprocess the loaded data frame\n",
    "with `pandas.melt` and use the function `seaborn.scatterplot` with specified \n",
    "grouping argument (`hue`) for the visualization.\n",
    "\n",
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "sb.set_theme() # Because seaborn theme looks awesome\n",
    "import pandas as pd\n",
    "\n",
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "**b)** Determine the _design matrix_ $X$ of the given data as a `numpy` array (don't \n",
    "forget the column of ones for the intercept $\\beta_0$). Using this matrix $X$, \n",
    "estimate the regression coefficients $\\beta$ of the linear model by the method of least \n",
    "squares and calculate the corresponding standard error of the estimates.  \n",
    "**Hint:** The estimated linear regression coefficients are given by \n",
    "$\\hat{\\beta} = (X^T X)^{-1} X^T Y$ and the standard error\n",
    "is given by the square root of the diagonal entries of $(X^TX)^{-1} \\hat{\\sigma}^2$ with \n",
    "$\\hat{\\sigma}^2 = \\frac{1}{n - p} \\sum_{i=1}^n (y_i- \\hat{y}_i)^2$.\n",
    "\n",
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "**c)** Calculate the $R^2$-value. What does the $R^2$-value mean in this context?\n",
    "\n",
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "**d)** What happens if we increase the first feature value $X_1$ by three? Which feature\n",
    "is the most important one?\n",
    "\n",
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "**e)** The data was sampled by the data generating process \n",
    "$$f(x) = x_1 + 2 x_2 + 3 x_3 + \\varepsilon.$$ \n",
    "Does the most important feature from part d) make sense regarding the data \n",
    "generating process? Explain your answer!\n",
    "\n",
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<hr style=\"border:1.5px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# 2) Logistic Regression\n",
    "\n",
    "## a) Introduction of odds ratio\n",
    "**i)** Suppose we have an ordinary and uniformly distributed six-sided\n",
    "dice described by a random variable $Y_1$. What are the odds of rolling a \n",
    "$5$ or a $6$?\n",
    "\n",
    "**Solution:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#AAAEBC\"> - your solution here - </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "**ii)** Let's consider a loaded dice $Y_2$ that rolls a $6$ with a probability of $\\frac{1}{3}$\n",
    "and a $5$ with a probability of $\\frac{1}{12}$. What are the odds for the event \n",
    "$Y_2 \\geq 5$ now?\n",
    "\n",
    "**Solution:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#AAAEBC\"> - your solution here - </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "**iii)** How have the odds changed from dice $Y_1$ to $Y_2$, i.e. by how much is it\n",
    "higher/lower? This factor is called the _odds ratio_.\n",
    "\n",
    "**Solution:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#AAAEBC\"> - your solution here - </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## b) Logistic Regression in Python\n",
    "In this exercise, a logistic model is fitted on the [iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set) indicating whether \n",
    "a given plant of the iris genus is a member of the species 'virginica' or not. For \n",
    "this purpose, we use the mighty package [`scikit-learn`](https://scikit-learn.org/stable/).\n",
    "\n",
    "**i)** Load the iris dataset from `sklearn.datasets` and save the features with \n",
    "corresponding output in one `pandas` dataframe. Then adjust the output to the \n",
    "binary classification problem described above.\n",
    "\n",
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "**ii)** Visualize this dataframe with `seaborn.pairplot` with grouping argument `virginica`.\n",
    "What do you think which feature incremented by one unit increases the odds for the class `virginica` the most? Explain your choice.\n",
    "\n",
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "**iii)** Fit a regression model with the function `sklearn.linear_model.LogisticRegression` and extract the estimated model parameters $\\beta$ from it. Now we want to determine \n",
    "the odds ratio of the parameters. Compared to the simple example from part a), \n",
    "a logistic model provides a probability conditional on the input data $x$, i.e. \n",
    "the odds is given by\n",
    "$$\n",
    "\\text{odds}_\\text{logreg} = \\frac{\\mathbb{P}(Y = 1 \\mid x)}{1- \\mathbb{P}(Y = 1 \\mid x)}.\n",
    "$$\n",
    "Therefore instead of using another dice, the stochastic model is now modified by increasing a component of $x$. Denote with $x_{x_i \\to x_i +1}$ a vector where the $i$-th component (feature) is increased by one unit. Thus, the following representation of the odds ratio for the i-th parameter results from the lecture:\n",
    "$$\n",
    "\\text{odds ratio}_i = \\frac{\\frac{\\mathbb{P}(Y = 1 \\mid x_{x_i \\to x_i +1})}{1- \\mathbb{P}(Y = 1 \\mid x_{x_i \\to x_i +1})}}{\\frac{\\mathbb{P}(Y = 1 \\mid x)}{1- \\mathbb{P}(Y = 1 \\mid x)}} = \\exp(\\beta_i).\n",
    "$$\n",
    "What are the odds ratios of your fitted logistic regression model, and which \n",
    "feature increases the odds for the class 'virginica' the most? How does your \n",
    "choice fit with your thoughts from part II)?\n",
    "\n",
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    " # 3) Prediction of Purchase Prices of Houses\n",
    "Load the dataset `sheet_2_house_price_data.csv`. This dataset contains the purchase prices of $10.000$ houses in Germany and includes the `size` (in mÂ²), `location` ($0=$ bad, $1=$ good, $2=$ very good and $3=$ luxury) and year of construction (`year`).\n",
    "\n",
    "**a)** Fit a linear regression model and calculate the mean squared error (MSE) of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** How can this dataset be examined to see whether feature interactions affect the output and, if so, which one? A visual explanation is enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Fit a linear regression model on these data by manually adding the relevant interactions. Then calculate the MSE again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Advanced: Logistic Regression\n",
    "Similar to linear regression, logistic regression assumes that there are no interactions between the features, even though this is rarely the case in reality. This also means that the odds ratio is constant for the estimated parameters $\\beta$ independent of the input data $x$, although the logistic model outputs a probability conditional on the data ($\\mathbb{P}(Y = 1 \\mid x)$).\n",
    "Let's consider the following logistic model with an interaction term and numerical features\n",
    "$$\n",
    "\\mathbb{P}(Y = 1 \\mid x) = f(x) = \\text{logistic}\\left(\\beta_0 + x_1 \\beta_1 + x_2 \\beta_2 + x_3 \\beta_3 + \\beta_{12} x_1 x_2 + \\beta_{33} x_3^2\\right).\n",
    "$$\n",
    "\n",
    "Calculate the odds ratio for each parameter $\\beta_1, \\beta_2$ and $\\beta_3$ if we\n",
    "increase the respective feature value by one unit.\n",
    "\n",
    "**Solution:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#AAAEBC\"> - your solution here - </span>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": "",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
